# Visual Instruction Tuning - Leveraging LLaVA for Behavioral Security Analysis
<div style="display: flex; justify-content: center; align-items: center; width: 100%;">
    <img src="assets/fight.png" alt="Image description 1" title="a title" style="width: 40%; max-width: 50%;">
    <img src="assets/consensual.jpg" alt="Image description 2" title="a title" style="width: 39%; max-width: 50%;">
</div>

## Introduction
Behavior analysis is a complex topic. To make matters worse, it becomes increasingly more difficult when we consider incorporating computers to automate this task.
However, if we had a well-tuned, responsive, and comprehensive algorithm for performaning inference on visual data, such that it was able to determine patterns of behavior, we would then be able to more effectively moderate and protect areas of interest (schools, childrens gaming environment, airports, etc.). In this repo, using LLaVA [[Haotian et al]](papers/2304.08485.pdf) we will explore current state of the are capabilities for perfoming visual inference on human interactions.

## Background 










